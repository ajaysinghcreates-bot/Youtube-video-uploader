name: Instagram Reels to YouTube Shorts (SEO Hinglish)

on:
  schedule:
    # Run daily at 9 AM UTC
    - cron: '0 9 * * *'
  workflow_dispatch:
    inputs:
      instagram_url:
        description: 'Instagram Reel URL (optional - for manual trigger)'
        required: false
        type: string

env:
  YOUTUBE_CLIENT_ID: ${{ secrets.YOUTUBE_CLIENT_ID }}
  YOUTUBE_CLIENT_SECRET: ${{ secrets.YOUTUBE_CLIENT_SECRET }}
  YOUTUBE_REFRESH_TOKEN: ${{ secrets.YOUTUBE_REFRESH_TOKEN }}
  OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}

jobs:
  upload:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repo
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.12"

      - name: Install dependencies
        run: |
          pip install yt-dlp openai google-auth google-auth-oauthlib google-auth-httplib2 google-api-python-client

      - name: Download Instagram Reel
        run: |
          mkdir -p downloads
          if [ -n "${{ github.event.inputs.instagram_url }}" ]; then
            yt-dlp -o "downloads/video.mp4" "${{ github.event.inputs.instagram_url }}"
          else
            echo "‚ùå No Instagram URL provided"
            exit 1
          fi

      - name: Extract transcript using OpenAI
        run: |
          python - <<EOF
          import openai, json

          client = openai.OpenAI(api_key="${{ secrets.OPENAI_API_KEY }}")

          audio_file = open("downloads/video.mp4", "rb")
          transcript = client.audio.transcriptions.create(
              model="gpt-4o-transcribe",
              file=audio_file
          )

          with open("downloads/transcript.json", "w", encoding="utf-8") as f:
              json.dump(transcript, f, indent=2)

          print("‚úÖ Transcript saved")
          EOF

      - name: Generate SEO metadata (Hinglish Shorts style)
        run: |
          python - <<EOF
          import json, openai, re

          with open("downloads/transcript.json", "r", encoding="utf-8") as f:
              transcript = json.load(f)

          text = transcript.get("text", "")

          prompt = f"""
          You are a YouTube Shorts SEO expert.  
          Based ONLY on this transcript, generate metadata for a viral YouTube Shorts video.  

          Transcript:
          {text}

          Rules:
          - Title:
            * Must be Hinglish (mix Hindi + English naturally).
            * Use emojis üé¨üî•ü§£üòç wherever relevant.
            * End with "#shorts".
            * Max 10-12 words.
          - Description:
            * 300-500 words.
            * Written in Hinglish (Hindi + English).
            * Summarize transcript content + add fun/context.
            * Must include at least 15 trending hashtags (#funny #shorts #viral etc).
            * End with a CTA like: "üëâ Like, Share & Subscribe for more! üîî".
          - Tags:
            * 20-30 keywords, Hinglish style.
            * Short phrases only.
            * Directly related to transcript content, no random terms.
            * Include "shorts", "viral shorts", "trending shorts".

          Respond in valid JSON only:
          {{
            "title": "...",
            "description": "...",
            "tags": ["...","..."]
          }}
          """

          client = openai.OpenAI(api_key="${{ secrets.OPENAI_API_KEY }}")

          response = client.chat.completions.create(
              model="gpt-4o-mini",
              messages=[{"role": "user", "content": prompt}],
              max_tokens=1000,
              temperature=0.8
          )

          content = response.choices[0].message.content
          match = re.search(r"\{.*\}", content, re.DOTALL)

          seo_json = {}
          if match:
              try:
                  seo_json = json.loads(match.group())
              except:
                  seo_json = {"title":"Viral Video #shortsüî•","description":"No description","tags":["shorts","viral"]}
          else:
              seo_json = {"title":"Viral Video #shortsüî•","description":"No description","tags":["shorts","viral"]}

          with open("downloads/seo_content.json", "w", encoding="utf-8") as f:
              json.dump(seo_json, f, indent=2)

          print("‚úÖ Hinglish SEO metadata ready")
          EOF

      - name: Upload video to YouTube Shorts
        run: |
          python - <<EOF
          import json
          from google.oauth2.credentials import Credentials
          from googleapiclient.discovery import build

          with open("downloads/seo_content.json", "r", encoding="utf-8") as f:
              seo = json.load(f)

          creds = Credentials(
              None,
              refresh_token="${{ secrets.YOUTUBE_REFRESH_TOKEN }}",
              client_id="${{ secrets.YOUTUBE_CLIENT_ID }}",
              client_secret="${{ secrets.YOUTUBE_CLIENT_SECRET }}",
              token_uri="https://oauth2.googleapis.com/token"
          )

          youtube = build("youtube", "v3", credentials=creds)

          request = youtube.videos().insert(
              part="snippet,status",
              body={
                  "snippet": {
                      "title": seo["title"],
                      "description": seo["description"],
                      "tags": seo["tags"],
                      "categoryId": "22"  # People & Blogs
                  },
                  "status": {
                      "privacyStatus": "public",
                      "selfDeclaredMadeForKids": False
                  }
              },
              media_body="downloads/video.mp4"
          )

          response = request.execute()
          print("‚úÖ Uploaded to YouTube:", response["id"])
          EOF
