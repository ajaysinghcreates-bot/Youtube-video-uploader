name: Instagram Reels to YouTube Shorts (Vosk + SEO)

on:
  workflow_dispatch:
    inputs:
      instagram_url:
        description: 'Instagram Reel URL'
        required: true
        type: string

env:
  YOUTUBE_CLIENT_ID: ${{ secrets.YOUTUBE_CLIENT_ID }}
  YOUTUBE_CLIENT_SECRET: ${{ secrets.YOUTUBE_CLIENT_SECRET }}
  YOUTUBE_REFRESH_TOKEN: ${{ secrets.YOUTUBE_REFRESH_TOKEN }}
  OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}

jobs:
  upload-short:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout
      uses: actions/checkout@v4

    - name: Install dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y ffmpeg unzip
        python3 -m pip install --upgrade pip
        pip install yt-dlp openai google-api-python-client google-auth google-auth-oauthlib google-auth-httplib2 ffmpeg-python vosk

    - name: Download Instagram Reel
      id: download
      run: |
        cat <<EOF | python3
        import yt_dlp, os, json

        url = '${{ github.event.inputs.instagram_url }}'
        os.makedirs('downloads', exist_ok=True)

        ydl_opts = {
          'format': 'best[height<=1920]/best',
          'outtmpl': 'downloads/%(id)s.%(ext)s',
          'writeinfojson': True,
          'http_headers': {'User-Agent': 'Mozilla/5.0'}
        }

        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            info = ydl.extract_info(url, download=True)

        # Save metadata
        metadata_path = 'downloads/metadata.json'
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(info, f, ensure_ascii=False, indent=2)

        # Get the video file
        video_file = None
        for ext in ['.mp4', '.mkv', '.webm']:
            for f in os.listdir('downloads'):
                if f.endswith(ext):
                    video_file = f
                    break
            if video_file:
                break

        if not video_file:
            raise Exception('Video download failed.')

        video_path = f'downloads/{video_file}'
        with open(os.environ['GITHUB_OUTPUT'], 'a') as fh:
            fh.write(f'video_file={video_path}\n')
            fh.write('success=true\n')
        EOF

    - name: Extract audio
      if: steps.download.outputs.success == 'true'
      run: |
        ffmpeg -y -i "${{ steps.download.outputs.video_file }}" -vn -acodec pcm_s16le -ar 16000 -ac 1 downloads/audio.wav

    - name: Transcribe audio with Vosk
      if: steps.download.outputs.success == 'true'
      run: |
        curl -L -o model.zip https://alphacephei.com/vosk/models/vosk-model-small-en-us-0.15.zip
        unzip -q model.zip -d .
        mv vosk-model-small-en-us-0.15 model

        cat <<EOF | python3
        import wave, json
        from vosk import Model, KaldiRecognizer

        wf = wave.open("downloads/audio.wav", "rb")
        if wf.getnchannels() != 1 or wf.getsampwidth() != 2:
            raise ValueError("Audio must be mono PCM.")

        model = Model("model")
        rec = KaldiRecognizer(model, wf.getframerate())
        rec.SetWords(True)

        result_text = ""
        while True:
            data = wf.readframes(4000)
            if len(data) == 0:
                break
            if rec.AcceptWaveform(data):
                res = json.loads(rec.Result())
                result_text += res.get("text", "") + " "

        final_result = {"text": result_text.strip()}
        with open("downloads/transcript.json", "w", encoding="utf-8") as f:
            json.dump(final_result, f, ensure_ascii=False, indent=2)
        EOF

    - name: Generate YouTube Shorts metadata
      if: steps.download.outputs.success == 'true'
      run: |
        cat <<EOF | python3
        import os, json, re, openai

        openai.api_key = os.getenv('OPENAI_API_KEY')

        # Load transcript and Instagram metadata
        with open('downloads/transcript.json', 'r', encoding='utf-8') as f:
            transcript = json.load(f)

        with open('downloads/metadata.json', 'r', encoding='utf-8') as f:
            metadata = json.load(f)

        text = transcript.get('text', '')
        insta_title = metadata.get('title', '')

        prompt = f"""
        You are a YouTube Shorts SEO expert.
        Using the Instagram title: '{insta_title}' and the transcript: '{text}', generate:

        - A catchy YouTube Shorts title under 100 chars (use emojis + #shorts, mix Hindi & English)
        - A description under 5000 words with keywords + hashtags
        - 20 SEO-friendly tags

        Return JSON only:
        {{
          "title":"...",
          "description":"...",
          "tags":["tag1","tag2",...]
        }}
        """

        response = openai.chat.completions.create(
            model='gpt-4o-mini',
            messages=[{'role':'user','content':prompt}],
            temperature=0.7,
            max_tokens=1200
        )

        content = response.choices[0].message.content
        match = re.search(r'\{.*\}', content, re.DOTALL)

        seo = {
            "title": "ðŸ”¥ Shorts Video #shorts",
            "description": "Watch now!",
            "tags": ["shorts"]
        }
        if match:
            try:
                seo = json.loads(match.group())
            except:
                pass

        with open('downloads/seo_content.json', 'w', encoding='utf-8') as f:
            json.dump(seo, f, indent=2)
        EOF

    - name: Upload to YouTube
      if: steps.download.outputs.success == 'true'
      run: |
        cat <<EOF | python3
        import os, json
        from glob import glob
        from mimetypes import guess_type
        from google.oauth2.credentials import Credentials
        from googleapiclient.discovery import build
        from googleapiclient.http import MediaFileUpload

        with open('downloads/seo_content.json', 'r') as f:
            seo = json.load(f)

        video_files = [f for f in glob('downloads/*') if f.endswith(('.mp4','.mkv','.webm'))]
        if not video_files:
            raise Exception('No video found')
        video_file = video_files[0]

        mime_type = guess_type(video_file)[0] or 'video/mp4'

        creds = Credentials(
            token=None,
            refresh_token=os.environ['YOUTUBE_REFRESH_TOKEN'],
            client_id=os.environ['YOUTUBE_CLIENT_ID'],
            client_secret=os.environ['YOUTUBE_CLIENT_SECRET'],
            token_uri='https://oauth2.googleapis.com/token'
        )

        youtube = build('youtube', 'v3', credentials=creds)

        request = youtube.videos().insert(
            part='snippet,status',
            body={
                'snippet': {
                    'title': seo.get('title'),
                    'description': seo.get('description'),
                    'tags': seo.get('tags'),
                    'categoryId':'24'
                },
                'status': {
                    'privacyStatus':'public',
                    'selfDeclaredMadeForKids': False
                }
            },
            media_body=MediaFileUpload(video_file, mimetype=mime_type)
        )

        response = request.execute()
        link = f"https://www.youtube.com/watch?v={response['id']}"
        print('âœ… Uploaded Video Link:', link)

        with open('downloads/video_link.txt', 'w') as f:
            f.write(link)
        EOF

    - name: Cleanup
      if: always()
      run: rm -rf downloads/ model/ model.zip
