name: Instagram Reels to YouTube Shorts (With Transcript SEO)

on:
  schedule:
    # Run daily at 9 AM UTC
    - cron: '0 9 * * *'
  workflow_dispatch:
    inputs:
      instagram_url:
        description: 'Instagram Reel URL (optional - for manual trigger)'
        required: false
        type: string

env:
  YOUTUBE_CLIENT_ID: ${{ secrets.YOUTUBE_CLIENT_ID }}
  YOUTUBE_CLIENT_SECRET: ${{ secrets.YOUTUBE_CLIENT_SECRET }}
  YOUTUBE_REFRESH_TOKEN: ${{ secrets.YOUTUBE_REFRESH_TOKEN }}
  OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}

jobs:
  process-reels:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Install dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y ffmpeg
        pip install --upgrade pip
        pip install yt-dlp google-auth google-auth-oauthlib google-auth-httplib2 google-api-python-client openai requests beautifulsoup4 whisper ffmpeg-python
        pip install --upgrade yt-dlp

    - name: Download Instagram Reel
      id: download
      run: |
        python - <<EOF
        import yt_dlp, json, os, sys, re
        from urllib.parse import urlparse

        def download_reel(url):
            ydl_opts = {
                'format': 'best[height<=1920]/best',
                'outtmpl': 'downloads/%(id)s.%(ext)s',
                'writeinfojson': True,
                'no_warnings': False,
                'extract_flat': False,
                'http_headers': {
                    'User-Agent': 'Mozilla/5.0'
                }
            }
            
            os.makedirs('downloads', exist_ok=True)
            
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                try:
                    info = ydl.extract_info(url, download=True)
                    metadata = {
                        'title': info.get('title', 'Instagram Reel'),
                        'description': info.get('description', ''),
                        'uploader': info.get('uploader', 'Unknown'),
                        'duration': info.get('duration', 0),
                        'id': info.get('id', ''),
                        'webpage_url': info.get('webpage_url', url)
                    }
                    with open('downloads/metadata.json', 'w') as f:
                        json.dump(metadata, f, indent=2)

                    video_files = [f for f in os.listdir('downloads') if f.endswith(('.mp4', '.mkv', '.webm', '.mov'))]
                    if video_files:
                        video_file = video_files[0]
                        with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
                            f.write(f"video_file=downloads/{video_file}\n")
                            f.write(f"success=true\n")
                        print(f"✅ Downloaded: {video_file}")
                        return True
                    else:
                        print("❌ No video file found")
                        return False
                except Exception as e:
                    print(f"Error: {e}")
                    return False

        instagram_url = "${{ github.event.inputs.instagram_url }}"
        if not instagram_url:
            print("No Instagram URL provided")
            sys.exit(0)

        success = download_reel(instagram_url)
        if not success:
            sys.exit(1)
        EOF

    - name: Extract Audio
      if: steps.download.outputs.success == 'true'
      run: |
        ffmpeg -i ${{ steps.download.outputs.video_file }} -vn -acodec pcm_s16le -ar 16000 -ac 1 downloads/audio.wav

    - name: Transcribe Audio to JSON
      if: steps.download.outputs.success == 'true'
      run: |
        python - <<EOF
        import whisper, json
        model = whisper.load_model("base")
        result = model.transcribe("downloads/audio.wav")
        with open("downloads/transcript.json", "w", encoding="utf-8") as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        EOF

    - name: Generate SEO from Transcript
      if: steps.download.outputs.success == 'true'
      run: |
        python - <<EOF
        import json, os, re, openai

        with open("downloads/transcript.json", "r", encoding="utf-8") as f:
            transcript = json.load(f)

        full_text = transcript.get("text", "")

        client = openai.OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

        prompt = f"""
        Based on this transcript, generate optimized YouTube Shorts metadata.

        Transcript:
        {full_text}

        Return JSON only:
        {{
          "title": "catchy short title",
          "description": "200-300 word engaging description with hashtags",
          "tags": ["tag1","tag2","tag3"]
        }}
        """

        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=1200,
            temperature=0.7
        )

        content = response.choices[0].message.content
        match = re.search(r"\{.*\}", content, re.DOTALL)

        seo_json = {}
        if match:
            try:
                seo_json = json.loads(match.group())
            except:
                seo_json = {"title": "Fallback Title", "description": "Fallback Description", "tags":["shorts"]}
        else:
            seo_json = {"title": "Fallback Title", "description": "Fallback Description", "tags":["shorts"]}

        with open("downloads/seo_content.json", "w", encoding="utf-8") as f:
            json.dump(seo_json, f, indent=2)

        print("✅ SEO content generated from transcript")
        EOF

    - name: Upload to YouTube
      if: steps.download.outputs.success == 'true'
      run: |
        python - <<EOF
        import json, os, glob
        from google.oauth2.credentials import Credentials
        from googleapiclient.discovery import build
        from googleapiclient.http import MediaFileUpload

        def get_youtube_service():
            credentials = Credentials(
                token=None,
                refresh_token=os.getenv('YOUTUBE_REFRESH_TOKEN'),
                token_uri='https://oauth2.googleapis.com/token',
                client_id=os.getenv('YOUTUBE_CLIENT_ID'),
                client_secret=os.getenv('YOUTUBE_CLIENT_SECRET')
            )
            return build('youtube', 'v3', credentials=credentials)

        with open('downloads/seo_content.json', 'r') as f:
            seo_content = json.load(f)

        video_files = glob.glob('downloads/*.mp4') + glob.glob('downloads/*.mkv') + glob.glob('downloads/*.webm')
        if not video_files:
            print("❌ No video found")
            exit(1)

        video_file = video_files[0]
        youtube = get_youtube_service()

        body = {
            'snippet': {
                'title': seo_content['title'],
                'description': seo_content['description'],
                'tags': seo_content['tags'],
                'categoryId': '24',
                'defaultLanguage': 'en'
            },
            'status': {
                'privacyStatus': 'public',
                'selfDeclaredMadeForKids': False
            }
        }

        media = MediaFileUpload(video_file, chunksize=-1, resumable=True, mimetype='video/*')

        try:
            request = youtube.videos().insert(part='snippet,status', body=body, media_body=media)
            response = request.execute()
            print(f"✅ Uploaded! Video URL: https://www.youtube.com/watch?v={response['id']}")
        except Exception as e:
            print(f"❌ Upload failed: {e}")
            exit(1)
        EOF

    - name: Cleanup
      if: always()
      run: rm -rf downloads/
